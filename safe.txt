net_states = gibbs_update(rand_states, vb, hb, W, gibbs_k)[1]

samples = torch.zeros(rand_states.shape[0], 2, dtype=model.precision, device=model.device)
nets = torch.zeros(rand_states.shape[0], 2, dtype=model.precision, device=model.device)
#print(torch.mean(rand_states))
#print(accept_per, accept_per/cycles)

for j, (rand_state, net_state) in enumerate(zip(rand_states, net_states)):
    samples[j, :] = basis[rand_state==one_tensor]
    nets[j, :] = basis[net_state==one_tensor]

------------------------
dPsidhb = torch.zeros(cycles, hb.shape[0], dtype=model.precision, device=model.device)
dPsidW = torch.zeros(cycles, W.shape[0], W.shape[1], dtype=model.precision, device=model.device)

for s_n, sample in enumerate(samples):
    for h_n in range(hidden.shape[1]):
        sum = 0
        for v_n in range(visual.shape[1]):
            sum += sample[v_n]*W[v_n, h_n]
        
        for v_n in range(visual.shape[1]):
            dPsidW[s_n, v_n, h_n] = (sample[v_n]/(2*(torch.exp(-hidden[h_n]-sum) + 1)))[0]

        dPsidhb[s_n, h_n] = 1/(2*(torch.exp(-hidden[h_n]-sum) + 1))[0]

-------------------------------

for i in range(cycles-1):
        
        new_energy = net_Energy(samples[i+1], vb, sample_hidden(samples[i+1], hb, W)[1], hb, W)
        old_energy = net_Energy(samples[i], vb, sample_hidden(samples[i], hb, W)[1], hb, W)
        accept_prob = new_energy/old_energy
        if (accept_prob >= rand_tensor[i]):
            pass
        else:
            samples[i+1] = samples[i]

----------------------------------

def make_energy_func(hamiltonian):    
    def state_Energy(sampled, net):
        norm = (sampled[:,None, :]@net[:,:,None]).squeeze()
        energy = ((sampled@hamiltonian)[:,None, :]@net[:,:,None]).squeeze()
        norm_energy = torch.zeros_like(norm)
        mask = norm!=0
        norm_energy[mask] = energy[mask]/norm[mask]
        return norm_energy
    return state_Energy
\-----------------------------------

doubles = torch.sum(dist_s-uniform_s, dim=1)
doubles[torch.abs(doubles) != 2] = 0
H_1 = V*0.5*doubles

-------------------------------------

def sum_lipkin_local(dist_s, uniform_s, eps, V, W):
    sum = torch.zeros_like(torch.sum(dist_s, dim=1))
    for state in uniform_s:
        mask = torch.all(dist_s == state, dim=1)
        H_0 = torch.zeros_like(dist_s[:, 0])
        H_0[mask] = eps*(2*torch.sum(dist_s[mask], dim=1) - 2).to(dtype=H_0.dtype)
        doubles = torch.sum(dist_s-state, dim=1)
        doubles[torch.abs(doubles) != 2] = 0
        H_1 = V*0.5*doubles
        H_2 = W*(torch.abs(torch.sum(dist_s-state, dim=1)) == 1)
        sum += H_0 + H_1 + H_2
    return 0.5*sum